{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMlJYTlaPezECvHetorR1gj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerrytsai961117/7021/blob/main/Untitled13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8NP0Prvttay"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai pandas numpy scikit-learn nltk opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "import opendatasets as od\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import time # For timing operations"
      ],
      "metadata": {
        "id": "L6qaQrYIt4p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import userdata\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    print(\"API key loaded from Colab Secrets.\")\n",
        "except Exception:\n",
        "    print(\"Please ensure you've set your GOOGLE_API_KEY in Colab Secrets. If not, replace 'YOUR_API_KEY' below manually.\")\n",
        "    # genai.configure(api_key=\"YOUR_API_KEY\") # Replace with your actual API key\n",
        "\n",
        "# Initialize the embedding model. 'text-embedding-004' is a robust choice.\n",
        "embedding_model_name = \"models/text-embedding-004\"\n",
        "print(f\"Embedding model '{embedding_model_name}' initialized.\")"
      ],
      "metadata": {
        "id": "KFLzV2UPt5gl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attempt to download the dataset from Kaggle. You'll be prompted for Kaggle API credentials.\n",
        "try:\n",
        "    od.download(\"https://www.kaggle.com/datasets/tharunprabu/songs-data-with-full-lyrics\")\n",
        "    df = pd.read_csv(\"songs-data-with-full-lyrics/songs_with_lyrics.csv\")\n",
        "    print(\"Dataset downloaded and loaded successfully from Kaggle!\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not download dataset from Kaggle. Error: {e}\")\n",
        "    print(\"Attempting to load from a local file path (assuming you've uploaded 'songs_with_lyrics.csv'):\")\n",
        "    try:\n",
        "        df = pd.read_csv(\"songs_with_lyrics.csv\")\n",
        "        print(\"Loaded from local file successfully!\")\n",
        "    except FileNotFoundError:\n",
        "        print(\"Could not find 'songs_with_lyrics.csv'. Creating a sample DataFrame for testing.\")\n",
        "        # Create a sample DataFrame with at least 100 entries for testing purposes\n",
        "        data = {\n",
        "            'Song Name': [f'Song {i}' for i in range(1, 151)],\n",
        "            'Artist': [f'Artist {i}' for i in range(1, 151)],\n",
        "            'Lyrics': [\n",
        "                \"This is a happy song about sunshine and flowers. Feeling good today, everything is bright.\",\n",
        "                \"A sad melody, about lost love and rainy days. Tears fall like rain.\",\n",
        "                \"Rock and roll all night, party every day. Electric guitar and loud drums.\",\n",
        "                \"Smooth jazz rhythms, chill vibes, late night city lights. Relax and unwind.\",\n",
        "                \"Hip hop beats, rhymes, and urban tales. Breaking down barriers, raising our voices.\",\n",
        "                \"Country roads, take me home, to the place I belong. Simple life, open fields.\",\n",
        "                \"Upbeat pop, dancing, feeling free. Summer nights and endless fun.\",\n",
        "                \"Another happy tune, full of joy and laughter. Life is a wonderful journey.\",\n",
        "                \"Deep thoughts, philosophical lyrics, questioning existence. The universe within.\",\n",
        "                \"Romantic ballad, hearts entwined, forever together. Love is eternal.\",\n",
        "                # Adding more diverse content for better embedding examples\n",
        "                \"A powerful anthem of rebellion and freedom. Break the chains, fight for justice, never surrender.\",\n",
        "                \"A calm, soothing lullaby for quiet nights. Sleep softly, dream sweet dreams, wake to a new dawn.\",\n",
        "                \"Energetic dance track with pulsating bass and shimmering synths. Feel the rhythm, let go, just move.\",\n",
        "                \"Thought-provoking folk song with intricate storytelling and acoustic guitar. Life's journey, lessons learned.\",\n",
        "                \"Heavy metal roar, screaming vocals, and shredding guitars. Unleash the beast, rage against the machine.\",\n",
        "                \"Soulful R&B groove, smooth vocals, and undeniable charm. Love's embrace, tender moments, deep connection.\",\n",
        "                \"Experimental electronic music, glitchy sounds, and ambient textures. Explore new soundscapes, abstract art.\",\n",
        "                \"A classical symphony, grand and timeless, echoing through the ages. Majestic, powerful, truly inspiring.\",\n",
        "                \"Upbeat reggae beats, positive vibes, and messages of peace. One love, unity, good vibrations for all.\",\n",
        "                \"Bluesy lament, raw emotion, and wailing harmonica. Heartbreak, struggle, finding solace in the sound.\",\n",
        "                # Populate with more generic content to reach 150 entries\n",
        "            ] + [f\"This is a generic song about various topics {i}. It has some random words and phrases to fill up the content for testing purposes. More text to ensure sufficient length for the dataset, reaching over 100 entries. Blah blah blah. Keywords: generic, random, text, test, long, fill, content.\" for i in range(11, 151)]\n",
        "        }\n",
        "        df = pd.DataFrame(data)\n",
        "        print(\"Created a sample DataFrame for testing.\")\n",
        "\n",
        "# Ensure 'Lyrics' column exists before proceeding\n",
        "if 'Lyrics' not in df.columns or df['Lyrics'].empty:\n",
        "    print(\"Error: 'Lyrics' column is missing or empty. Cannot proceed with embedding generation.\")\n",
        "    # Exit or raise an error in a production environment\n",
        "    exit()\n",
        "\n",
        "# Download NLTK resources if not already present\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('wordnet')\n",
        "\n",
        "# Define text cleaning function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text).lower() # Convert to string and lowercase\n",
        "    text = re.sub(r'\\[.*?\\]', '', text) # Remove text in square brackets (e.g., [Chorus])\n",
        "    text = re.sub(r'[^a-z\\s]', '', text) # Keep only letters and spaces\n",
        "    tokens = word_tokenize(text) # Tokenize\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words and word.strip()] # Lemmatize, remove stopwords, and empty strings\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply preprocessing to 'Lyrics' column\n",
        "df['Cleaned_Lyrics'] = df['Lyrics'].apply(preprocess_text)\n",
        "\n",
        "# Filter out entries where Cleaned_Lyrics might have become empty after preprocessing\n",
        "df_processed = df[df['Cleaned_Lyrics'].str.strip() != ''].reset_index(drop=True)\n",
        "print(f\"Data preprocessing complete. Number of valid entries: {len(df_processed)}\")\n",
        "\n",
        "if len(df_processed) < 50:\n",
        "    print(\"Warning: Less than 50 valid entries after preprocessing. Recommendation quality might be limited.\")\n",
        "\n",
        "# Ensure there are enough songs for recommendation\n",
        "if len(df_processed) < 2:\n",
        "    print(\"Error: Not enough songs in the dataset for recommendations. Please ensure at least two songs with valid lyrics.\")\n",
        "    exit()"
      ],
      "metadata": {
        "id": "4JyYHHLMt6Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Generating embeddings for songs in the dataset (this may take a moment)... ---\")\n",
        "start_time = time.time()\n",
        "\n",
        "# To manage API calls and runtime, we'll embed up to the first 500 songs.\n",
        "# In a full-scale application, you'd embed your entire dataset.\n",
        "texts_for_embedding = df_processed['Cleaned_Lyrics'].tolist()\n",
        "num_to_embed = min(len(texts_for_embedding), 500)\n",
        "texts_to_embed_subset = texts_for_embedding[:num_to_embed]\n",
        "\n",
        "all_song_embeddings = []\n",
        "# The embed_content API efficiently handles batch requests.\n",
        "try:\n",
        "    response = genai.embed_content(\n",
        "        model=embedding_model_name,\n",
        "        contents=texts_to_embed_subset,\n",
        "        task_type=\"SEMANTIC_SIMILARITY\" # Specify task type for better embeddings\n",
        "    )\n",
        "    all_song_embeddings = [np.array(e.values) for e in response.embeddings]\n",
        "    print(f\"Successfully generated {len(all_song_embeddings)} song embeddings.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error generating song embeddings: {e}\")\n",
        "    all_song_embeddings = []\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Embedding generation took: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "if not all_song_embeddings:\n",
        "    print(\"Error: Failed to generate song embeddings. Please check API key and network connection. Cannot proceed with recommendations.\")\n",
        "    exit()\n",
        "\n",
        "# Attach embeddings to the DataFrame for easy access\n",
        "df_processed_with_embeddings = df_processed.head(len(all_song_embeddings)).copy()\n",
        "df_processed_with_embeddings['embedding'] = list(all_song_embeddings)\n",
        "\n",
        "# Convert all song embeddings to a single NumPy array for efficient cosine similarity calculation\n",
        "song_embeddings_matrix = np.array(df_processed_with_embeddings['embedding'].tolist())\n",
        "\n",
        "print(f\"All song embeddings stored as a NumPy array with shape: {song_embeddings_matrix.shape}\")"
      ],
      "metadata": {
        "id": "ZN2fYtnHt7ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recommendations_from_text(user_input_text, dataframe_with_embeddings, embeddings_matrix, top_n=5):\n",
        "    \"\"\"\n",
        "    Recommends the most similar songs based on user's text input.\n",
        "\n",
        "    Args:\n",
        "        user_input_text (str): The user's text description of a song/style.\n",
        "        dataframe_with_embeddings (pd.DataFrame): DataFrame containing 'Song Name', 'Artist', and 'embedding'.\n",
        "        embeddings_matrix (np.array): A 2D NumPy array of all song embeddings.\n",
        "        top_n (int): The number of top similar songs to recommend.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame of the top_n recommended songs, including their 'Song Name', 'Artist', and 'Similarity_Score'.\n",
        "                      Returns an empty DataFrame if input is invalid or no recommendations are found.\n",
        "    \"\"\"\n",
        "    if not user_input_text.strip():\n",
        "        print(\"User input cannot be empty.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    print(f\"\\nProcessing your input: '{user_input_text}'...\")\n",
        "\n",
        "    # 1. Preprocess user input\n",
        "    cleaned_user_input = preprocess_text(user_input_text)\n",
        "    if not cleaned_user_input:\n",
        "        print(\"Preprocessed user input is empty. Cannot generate embedding.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 2. Generate embedding for user input\n",
        "    try:\n",
        "        user_embedding_response = genai.embed_content(\n",
        "            model=embedding_model_name,\n",
        "            contents=[cleaned_user_input], # The API expects a list of contents\n",
        "            task_type=\"SEMANTIC_SIMILARITY\"\n",
        "        )\n",
        "        user_embedding = np.array(user_embedding_response.embeddings[0].values)\n",
        "        if user_embedding.ndim == 1:\n",
        "            user_embedding = user_embedding.reshape(1, -1) # Reshape to 2D for cosine_similarity\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating embedding for user input: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # 3. Calculate cosine similarity between user input and all song embeddings\n",
        "    # cosine_similarity expects two 2D arrays (n_samples, n_features)\n",
        "    similarities = cosine_similarity(user_embedding, embeddings_matrix).flatten()\n",
        "\n",
        "    # 4. Create a Series of similarity scores, indexed by song index\n",
        "    similarity_scores = pd.Series(similarities, index=dataframe_with_embeddings.index)\n",
        "\n",
        "    # 5. Get the top N most similar songs\n",
        "    # .nlargest automatically sorts and takes the top values\n",
        "    top_similar_indices = similarity_scores.nlargest(top_n).index\n",
        "\n",
        "    # 6. Retrieve details of recommended songs\n",
        "    recommendations = dataframe_with_embeddings.loc[top_similar_indices, ['Song Name', 'Artist']].copy()\n",
        "    recommendations['Similarity_Score'] = similarity_scores.loc[top_similar_indices]\n",
        "\n",
        "    return recommendations.reset_index(drop=True)\n",
        "\n",
        "print(\"`get_recommendations_from_text` function defined.\")"
      ],
      "metadata": {
        "id": "RXBz55Axt8YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_recommender_prototype():\n",
        "    print(\"\\n--- Welcome to the AI Song Recommender! ---\")\n",
        "    print(\"Describe the type of song, theme, or mood you're looking for, and I'll recommend similar songs.\")\n",
        "    print(\"Type 'exit' or 'quit' to stop.\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nPlease describe the song you'd like (e.g., 'a sad song about lost love', 'energetic party music for dancing'): \\n> \")\n",
        "\n",
        "        if user_input.lower() in ['exit', 'quit']:\n",
        "            print(\"Thanks for using the recommender! Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not user_input.strip():\n",
        "            print(\"Your input was empty. Please type a description.\")\n",
        "            continue\n",
        "\n",
        "        # Get recommendations\n",
        "        recommended_songs = get_recommendations_from_text(\n",
        "            user_input_text=user_input,\n",
        "            dataframe_with_embeddings=df_processed_with_embeddings,\n",
        "            embeddings_matrix=song_embeddings_matrix,\n",
        "            top_n=5 # Recommend the top 5 songs\n",
        "        )\n",
        "\n",
        "        if not recommended_songs.empty:\n",
        "            print(\"\\n--- Here are your song recommendations: ---\")\n",
        "            print(recommended_songs.to_string(index=False)) # Use to_string for better DataFrame printing\n",
        "        else:\n",
        "            print(\"\\nSorry, I couldn't find relevant recommendations based on your description. Please try a different one.\")\n",
        "\n",
        "# --- Run the main prototype ---\n",
        "if __name__ == \"__main__\":\n",
        "    if 'df_processed_with_embeddings' in locals() and not df_processed_with_embeddings.empty:\n",
        "        run_recommender_prototype()\n",
        "    else:\n",
        "        print(\"\\nSystem initialization failed. Please check previous steps for data loading and embedding generation errors.\")"
      ],
      "metadata": {
        "id": "hRDBYnnit9VA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}