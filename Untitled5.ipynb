{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnPCFnd/Wa/tHPMuD0FCeD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jerrytsai961117/7021/blob/main/Untitled5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZinQ6CTo0Lk"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os"
      ],
      "metadata": {
        "id": "YCwCNwmgo6TU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 這裡我們將從 Colab 的秘密 (Secrets) 中獲取 API 金鑰\n",
        "# 如果您是第一次使用，請點擊 Colab 左側的「🔑」圖標，添加一個名為 GOOGLE_API_KEY 的秘密\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n",
        "    print(\"API 金鑰已從 Colab Secrets 加載。\")\n",
        "except Exception:\n",
        "    print(\"請確保您已在 Colab Secrets 中設定 GOOGLE_API_KEY。若無法從 Secrets 加載，請手動替換 'YOUR_API_KEY'。\")\n",
        "    # 如果沒有設定 Secrets，這裡可以手動設定，但請注意安全性\n",
        "    # genai.configure(api_key=\"YOUR_API_KEY\")\n",
        "\n",
        "\n",
        "# 初始化 GenerativeModel\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "print(\"模型已初始化。\")"
      ],
      "metadata": {
        "id": "D8JftUrBo7E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer(prompt, temperature, max_tokens):\n",
        "    \"\"\"\n",
        "    根據給定的提示，使用指定的 temperature 和 max_output_tokens 生成答案。\n",
        "\n",
        "    Args:\n",
        "        prompt (str): 用於生成答案的提示。\n",
        "        temperature (float): 控制生成答案的隨機性，範圍通常在 0.0 到 1.0 之間。\n",
        "                             數值越低越確定，數值越高越隨機。\n",
        "        max_tokens (int): 生成答案的最大詞元數量。\n",
        "\n",
        "    Returns:\n",
        "        str: 模型生成的答案。\n",
        "    \"\"\"\n",
        "    # 創建 GenerationConfig 物件，將 temperature 和 max_output_tokens 傳遞給模型\n",
        "    generation_config = genai.GenerationConfig(\n",
        "        temperature=temperature,\n",
        "        max_output_tokens=max_tokens\n",
        "    )\n",
        "\n",
        "    # 調用 model.generate_content 並包含新的配置\n",
        "    try:\n",
        "        response = model.generate_content(prompt, generation_config=generation_config)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"生成答案時發生錯誤: {e}\"\n",
        "\n",
        "print(\"`generate_answer` 函數已定義。\")"
      ],
      "metadata": {
        "id": "0ExBkTSOo74g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # 定義一個固定的提示詞\n",
        "    final_prompt = \"請詳細描述人工智能在醫療保健領域的應用，包括診斷、藥物開發和個性化治療。\"\n",
        "    #final_prompt = \"Describe in detail the applications of artificial intelligence in healthcare, including diagnosis, drug development, and personalized treatment.\" # 英文版提示詞，如果希望模型回答英文\n",
        "\n",
        "    # 選擇一個單一的 temperature 設定\n",
        "    fixed_temperature = 0.5\n",
        "\n",
        "    # 定義不同的 max_tokens 值\n",
        "    max_tokens_values = [20, 50, 100, 200]\n",
        "\n",
        "    print(f\"原始提示詞:\\n---\\n{final_prompt}\\n---\\n\")\n",
        "    print(f\"固定溫度 (Temperature) = {fixed_temperature}\\n\")\n",
        "\n",
        "    for max_tok in max_tokens_values:\n",
        "        print(f\"\\n===== 最大詞元數 (Max Tokens) = {max_tok} =====\")\n",
        "        print(f\"呼叫 generate_answer(prompt, temperature={fixed_temperature}, max_tokens={max_tok})\")\n",
        "\n",
        "        # 呼叫修改後的 generate_answer 函數\n",
        "        answer = generate_answer(final_prompt, temperature=fixed_temperature, max_tokens=max_tok)\n",
        "        print(f\"模型輸出:\\n{answer}\")\n",
        "        # 注意: len(answer.split()) 是估計的詞數，實際 tokens 數可能略有不同，但會嚴格遵守 max_tokens 限制。\n",
        "        print(f\"--- 輸出字數 (約): {len(answer.split())} 字 ---\\n\")\n",
        "\n",
        "# 執行主函數\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "7nGoJN4Oo9HV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}